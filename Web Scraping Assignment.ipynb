{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a python program to display all the header tags from  ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Main Page',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Navigation menu',\n",
       " 'Personal tools',\n",
       " 'Namespaces',\n",
       " 'Variants',\n",
       " 'Views',\n",
       " 'More',\n",
       " 'Search',\n",
       " 'Navigation',\n",
       " 'Contribute',\n",
       " 'Tools',\n",
       " 'Print/export',\n",
       " 'In other projects',\n",
       " 'Languages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page1=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup1=BeautifulSoup(page1.content)\n",
    "all_header=soup1.find_all(['h1','h2','h3'])\n",
    "header=[]\n",
    "for i in all_header:\n",
    "    header.append(i.text.strip())\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Download IMDB's Top 100 data\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "imdb = []\n",
    "\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 100):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    \n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"Ranking\": place,\n",
    "            \"Movie Name\": title,\n",
    "            \"IMDB Rating\": ratings[index],\n",
    "            \"Year of Release\": year,}\n",
    "    imdb.append(data)\n",
    "    \n",
    "Top100=pd.DataFrame(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.219917983034774</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.147522087344743</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>8.980036571991164</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.97042495058285</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.935610935003025</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.261607244300963</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.259166280424893</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.258044308095322</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.257920800406175</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>8.256638228383022</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking                              Movie Name        IMDB Rating  \\\n",
       "0        1                The Shawshank Redemption  9.219917983034774   \n",
       "1        2                           The Godfather  9.147522087344743   \n",
       "2        3                  The Godfather: Part II  8.980036571991164   \n",
       "3        4                         The Dark Knight   8.97042495058285   \n",
       "4        5                            12 Angry Men  8.935610935003025   \n",
       "..     ...                                     ...                ...   \n",
       "95      96                                  Jagten  8.261607244300963   \n",
       "96      97                            Idi i smotri  8.259166280424893   \n",
       "97      98                     Singin' in the Rain  8.258044308095322   \n",
       "98      99                      North by Northwest  8.257920800406175   \n",
       "99      10   Eternal Sunshine of the Spotless Mind  8.256638228383022   \n",
       "\n",
       "   Year of Release  \n",
       "0             1994  \n",
       "1             1972  \n",
       "2             1974  \n",
       "3             2008  \n",
       "4             1957  \n",
       "..             ...  \n",
       "95            2012  \n",
       "96            1985  \n",
       "97            1952  \n",
       "98            1959  \n",
       "99            2004  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data  frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Download IMDB's Top 100 data\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2e9dfa9b-3e4d-4d39-acd2-8af11f252a59&pf_rd_r=MQQM8QJ9QAJYPDXRT27W&pf_rd_s=right-5&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_india_tr_rhs_1'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "imdb = []\n",
    "\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 100):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    \n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"Ranking\": place,\n",
    "            \"Movie Name\": title,\n",
    "            \"IMDB Rating\": ratings[index],\n",
    "            \"Year of Release\": year,}\n",
    "    imdb.append(data)\n",
    "    \n",
    "Top100=pd.DataFrame(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.493820190501882</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.486669178421991</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.479273838756345</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.476217920201057</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.464073507283429</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Andaz Apna Apna</td>\n",
       "      <td>8.067416268129461</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>8.065191518615428</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.06468983121663</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>PK</td>\n",
       "      <td>8.06315275373078</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>8.055525789928502</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking                Movie Name        IMDB Rating Year of Release\n",
       "0        1           Pather Panchali  8.493820190501882            1955\n",
       "1        2                   Nayakan  8.486669178421991            1987\n",
       "2        3         Pariyerum Perumal  8.479273838756345            2018\n",
       "3        4                Anbe Sivam  8.476217920201057            2003\n",
       "4        5                   Golmaal  8.464073507283429            1979\n",
       "..     ...                       ...                ...             ...\n",
       "95      96           Andaz Apna Apna  8.067416268129461            1994\n",
       "96      97  Uri: The Surgical Strike  8.065191518615428            2018\n",
       "97      98                 Virumandi   8.06468983121663            2004\n",
       "98      99                        PK   8.06315275373078            2014\n",
       "99      10                     Lucia  8.055525789928502            2013\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write  a  python  program  to  scrap  book  name,  author  name,  genre  and  book  review  of  any  5  books  from ‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to  scrape: i)  Top 10 ODI teams in men’s cricket along with the records for matches, points and  rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "banner_pos=soup.find('td',class_='rankings-block__banner--pos')\n",
    "banner_team=soup.find('td',class_='rankings-block__banner--team-name')\n",
    "banner_matches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "banner_points=soup.find('td', class_='rankings-block__banner--points')\n",
    "banner_rating=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "\n",
    "ranking=[]\n",
    "team=[]\n",
    "matches=[]\n",
    "points=[]\n",
    "team_rating=[]\n",
    "\n",
    "ranking.append(banner_pos.text.replace('\\n',''))\n",
    "team.append(banner_team.text.replace('\\n',' '))\n",
    "matches.append(banner_matches.text.replace('\\n',' '))\n",
    "team_rating.append(banner_rating.text.replace('\\n',' '))\n",
    "points.append(banner_points.text.replace('\\n',' '))\n",
    "\n",
    "pos=soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "country=soup.find_all('td',class_='table-body__cell rankings-table__team')\n",
    "matches_points=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "rating=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "\n",
    "for i in range(18):\n",
    "    if i%2==0:\n",
    "        matches.append(matches_points[i].text)\n",
    "    if i%2==1:\n",
    "        points.append(matches_points[i].text)\n",
    "        \n",
    "for i in range(9):\n",
    "    ranking.append(pos[i].text.replace('\\n',' '))\n",
    "    team.append(country[i].text.replace('\\n',' '))\n",
    "    team_rating.append(rating[i].text.replace('\\n',' '))\n",
    "        \n",
    "Top10_ODI=pd.DataFrame({'Ranking':(ranking),\n",
    "                       'Team':(team),\n",
    "                       'Matches':(matches),\n",
    "                       'Points':(points),\n",
    "                       'Rating':(team_rating)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Zealand NZ</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia AUS</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>India IND</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>England ENG</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Africa SA</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pakistan PAK</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh BAN</td>\n",
       "      <td>27</td>\n",
       "      <td>2,438</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>West Indies WI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka SL</td>\n",
       "      <td>24</td>\n",
       "      <td>1,876</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan AFG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranking                Team Matches Points  \\\n",
       "0       1     New Zealand NZ       17  2,054   \n",
       "1       2      Australia AUS       25  2,945   \n",
       "2       3          India IND       29  3,344   \n",
       "3       4        England ENG       27  3,100   \n",
       "4       5    South Africa SA       20  2,137   \n",
       "5       6       Pakistan PAK       24  2,323   \n",
       "6       7     Bangladesh BAN       27  2,438   \n",
       "7       8     West Indies WI       27  2,222   \n",
       "8       9       Sri Lanka SL       24  1,876   \n",
       "9      10    Afghanistan AFG       17  1,054   \n",
       "\n",
       "                                              Rating  \n",
       "0                               121              ...  \n",
       "1                                                118  \n",
       "2                                                115  \n",
       "3                                                115  \n",
       "4                                                107  \n",
       "5                                                 97  \n",
       "6                                                 90  \n",
       "7                                                 82  \n",
       "8                                                 78  \n",
       "9                                                 62  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top10_ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: ii)  Top 10 ODI Batsmen in men along with the records of their team and  rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Ranking               Player Team  \\\n",
       "0                                       1                   Babar Azam  PAK   \n",
       "1                                       2                  Virat Kohli  IND   \n",
       "2                                       3                 Rohit Sharma  IND   \n",
       "3                                       4                  Ross Taylor   NZ   \n",
       "4                                       5                  Aaron Finch  AUS   \n",
       "5                                       6               Jonny Bairstow  ENG   \n",
       "6                                       7                 Fakhar Zaman  PAK   \n",
       "7                                                  Francois du Plessis   SA   \n",
       "8                                       9                 David Warner  AUS   \n",
       "9                                                            Shai Hope   WI   \n",
       "\n",
       "  Rating  \n",
       "0    865  \n",
       "1    857  \n",
       "2    825  \n",
       "3    801  \n",
       "4    791  \n",
       "5    785  \n",
       "6    778  \n",
       "7    778  \n",
       "8    773  \n",
       "9    773  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "banner_pos=soup.find('div', class_=\"rankings-block__banner--pos\")\n",
    "banner_player=soup.find('div', class_=\"rankings-block__banner--name\")\n",
    "player_name.append(banner_player.text.replace('[',''))\n",
    "\n",
    "banner_nationality=soup.find('div', class_=\"rankings-block__banner--nationality\")\n",
    "\n",
    "str=banner_nationality.text.replace('\\n','')\n",
    "\n",
    "banner_team = ''\n",
    "banner_rating=''\n",
    "\n",
    "for i in str:\n",
    "    if i.isalpha():\n",
    "        banner_team += i\n",
    "    \n",
    "    if i.isdigit():\n",
    "        banner_rating += i\n",
    "\n",
    "\n",
    "position=soup.find_all('td',class_=\"table-body__cell table-body__cell--position u-text-right\")\n",
    "player=soup.find_all('td',class_='table-body__cell name')\n",
    "country=soup.find_all('td', class_=\"table-body__cell nationality-logo\")\n",
    "rating=soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "\n",
    "ranking=[]\n",
    "player_name=[]\n",
    "team=[]\n",
    "player_rating=[]\n",
    "\n",
    "ranking.append(banner_pos.text.replace('\\n',''))\n",
    "player_name.append(banner_player.text)\n",
    "team.append(banner_team)\n",
    "player_rating.append(banner_rating)\n",
    "\n",
    "for i in range(9):\n",
    "    ranking.append(position[i].text.replace('\\n',''))\n",
    "    player_name.append(player[i].text.replace('\\n',''))\n",
    "    team.append(country[i].text.replace('\\n',''))\n",
    "    player_rating.append(rating[i].text)\n",
    "        \n",
    "Top10_ODIBatsman=pd.DataFrame({'Ranking':(ranking),\n",
    "                               'Player':(player_name),\n",
    "                               'Team':(team),\n",
    "                               'Rating':(player_rating)})\n",
    "\n",
    "Top10_ODIBatsman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: iii)  Top 10 ODI bowlers along with the records of their team and  rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Ranking             Player Team  \\\n",
       "0                                       1                Trent Boult   NZ   \n",
       "1                                       2               Mehedi Hasan  BAN   \n",
       "2                                       3           Mujeeb Ur Rahman  AFG   \n",
       "3                                       4                 Matt Henry   NZ   \n",
       "4                                       5             Jasprit Bumrah  IND   \n",
       "5                                       6              Kagiso Rabada   SA   \n",
       "6                                       7               Chris Woakes  ENG   \n",
       "7                                       8             Josh Hazlewood  AUS   \n",
       "8                                       9                Pat Cummins  AUS   \n",
       "9                                      10          Mustafizur Rahman  BAN   \n",
       "\n",
       "  Rating  \n",
       "0    737  \n",
       "1    713  \n",
       "2    708  \n",
       "3    691  \n",
       "4    690  \n",
       "5    666  \n",
       "6    665  \n",
       "7    660  \n",
       "8    646  \n",
       "9    645  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "top_position=soup.find_all('div', class_=\"rankings-block__banner--pos\")\n",
    "top_player=soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "top_nationality=soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "\n",
    "banner_position=top_position[1].text.replace('\\n','')\n",
    "banner_player=top_player[1].text.replace('\\n','')\n",
    "str=top_nationality[1].text.replace('\\n','')\n",
    "\n",
    "banner_team = ''\n",
    "banner_rating=''\n",
    "\n",
    "for i in str:\n",
    "    if i.isalpha():\n",
    "        banner_team += i\n",
    "    \n",
    "    if i.isdigit():\n",
    "        banner_rating += i\n",
    "\n",
    "\n",
    "position=soup.find_all('td',class_=\"table-body__cell table-body__cell--position u-text-right\")\n",
    "player=soup.find_all('td',class_='table-body__cell name')\n",
    "country=soup.find_all('td', class_=\"table-body__cell nationality-logo\")\n",
    "rating=soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "\n",
    "ranking=[]\n",
    "player_name=[]\n",
    "team=[]\n",
    "player_rating=[]\n",
    "\n",
    "ranking.append(banner_position)\n",
    "player_name.append(banner_player)\n",
    "team.append(banner_team)\n",
    "player_rating.append(banner_rating)\n",
    "\n",
    "for i in range(9,18):\n",
    "    ranking.append(position[i].text.replace('\\n',''))\n",
    "    player_name.append(player[i].text.replace('\\n',''))\n",
    "    team.append(country[i].text.replace('\\n',''))\n",
    "    player_rating.append(rating[i].text)\n",
    "        \n",
    "Top10_ODIBowler=pd.DataFrame({'Ranking':(ranking),\n",
    "                               'Player':(player_name),\n",
    "                               'Team':(team),\n",
    "                               'Rating':(player_rating)})\n",
    "\n",
    "Top10_ODIBowler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: i)  Top 10 ODI teams in women’s cricket along with the records for matches, points and  rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia AUS</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa SA</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>England ENG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India IND</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand NZ</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies WI</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Pakistan PAK</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Bangladesh BAN</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka SL</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ireland IRE</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranking                Team Matches Points  \\\n",
       "0       1      Australia AUS       18  2,955   \n",
       "1       2    South Africa SA       24  2,828   \n",
       "2       3        England ENG       17  1,993   \n",
       "3       4          India IND       20  2,226   \n",
       "4       5     New Zealand NZ       21  1,947   \n",
       "5       6     West Indies WI       12  1,025   \n",
       "6       7       Pakistan PAK       15  1,101   \n",
       "7       8     Bangladesh BAN        5    306   \n",
       "8       9       Sri Lanka SL       11    519   \n",
       "9      10        Ireland IRE        2     25   \n",
       "\n",
       "                                              Rating  \n",
       "0                               164              ...  \n",
       "1                                                118  \n",
       "2                                                117  \n",
       "3                                                111  \n",
       "4                                                 93  \n",
       "5                                                 85  \n",
       "6                                                 73  \n",
       "7                                                 61  \n",
       "8                                                 47  \n",
       "9                                                 13  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "banner_pos=soup.find('td',class_='rankings-block__banner--pos')\n",
    "banner_team=soup.find('td',class_='rankings-block__banner--team-name')\n",
    "banner_matches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "banner_points=soup.find('td', class_='rankings-block__banner--points')\n",
    "banner_rating=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "\n",
    "ranking=[]\n",
    "team=[]\n",
    "matches=[]\n",
    "points=[]\n",
    "team_rating=[]\n",
    "\n",
    "ranking.append(banner_pos.text.replace('\\n',''))\n",
    "team.append(banner_team.text.replace('\\n',' '))\n",
    "matches.append(banner_matches.text.replace('\\n',' '))\n",
    "team_rating.append(banner_rating.text.replace('\\n',' '))\n",
    "points.append(banner_points.text.replace('\\n',' '))\n",
    "\n",
    "pos=soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "country=soup.find_all('td',class_='table-body__cell rankings-table__team')\n",
    "matches_points=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "rating=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "\n",
    "for i in range(18):\n",
    "    if i%2==0:\n",
    "        matches.append(matches_points[i].text)\n",
    "    if i%2==1:\n",
    "        points.append(matches_points[i].text)\n",
    "        \n",
    "for i in range(9):\n",
    "    ranking.append(pos[i].text.replace('\\n',' '))\n",
    "    team.append(country[i].text.replace('\\n',' '))\n",
    "    team_rating.append(rating[i].text.replace('\\n',' '))\n",
    "        \n",
    "Top10_ODI_Women=pd.DataFrame({'Ranking':(ranking),\n",
    "                       'Team':(team),\n",
    "                       'Matches':(matches),\n",
    "                       'Points':(points),\n",
    "                       'Rating':(team_rating)})\n",
    "Top10_ODI_Women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: ii)  Top 10 women’s ODI players along with the records of their team and  rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9        T...</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Ranking             Player Team  \\\n",
       "0                                          1             Tammy Beaumont  ENG   \n",
       "1                                          2                Lizelle Lee   SA   \n",
       "2                                          3               Alyssa Healy  AUS   \n",
       "3                                          4            Stafanie Taylor   WI   \n",
       "4                                          5                Meg Lanning  AUS   \n",
       "5                                          6          Amy Satterthwaite   NZ   \n",
       "6                                          7            Smriti Mandhana  IND   \n",
       "7                                          8                Mithali Raj  IND   \n",
       "8                                      9        T...     Natalie Sciver  ENG   \n",
       "9                                      10        ...    Laura Wolvaardt   SA   \n",
       "\n",
       "  Rating  \n",
       "0    765  \n",
       "1    758  \n",
       "2    756  \n",
       "3    746  \n",
       "4    723  \n",
       "5    715  \n",
       "6    710  \n",
       "7    709  \n",
       "8    685  \n",
       "9    683  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "banner_pos=soup.find('div', class_=\"rankings-block__banner--pos\")\n",
    "banner_player=soup.find('div', class_=\"rankings-block__banner--name\")\n",
    "player_name.append(banner_player.text.replace('[',''))\n",
    "\n",
    "banner_nationality=soup.find('div', class_=\"rankings-block__banner--nationality\")\n",
    "\n",
    "str=banner_nationality.text.replace('\\n','')\n",
    "\n",
    "banner_team = ''\n",
    "banner_rating=''\n",
    "\n",
    "for i in str:\n",
    "    if i.isalpha():\n",
    "        banner_team += i\n",
    "    \n",
    "    if i.isdigit():\n",
    "        banner_rating += i\n",
    "\n",
    "\n",
    "position=soup.find_all('td',class_=\"table-body__cell table-body__cell--position u-text-right\")\n",
    "player=soup.find_all('td',class_='table-body__cell name')\n",
    "country=soup.find_all('td', class_=\"table-body__cell nationality-logo\")\n",
    "rating=soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "\n",
    "ranking=[]\n",
    "player_name=[]\n",
    "team=[]\n",
    "player_rating=[]\n",
    "\n",
    "ranking.append(banner_pos.text.replace('\\n',''))\n",
    "player_name.append(banner_player.text)\n",
    "team.append(banner_team)\n",
    "player_rating.append(banner_rating)\n",
    "\n",
    "for i in range(9):\n",
    "    ranking.append(position[i].text.replace('\\n',''))\n",
    "    player_name.append(player[i].text.replace('\\n',''))\n",
    "    team.append(country[i].text.replace('\\n',''))\n",
    "    player_rating.append(rating[i].text)\n",
    "        \n",
    "Top10_ODI_Batswoman=pd.DataFrame({'Ranking':(ranking),\n",
    "                               'Player':(player_name),\n",
    "                               'Team':(team),\n",
    "                               'Rating':(player_rating)})\n",
    "\n",
    "Top10_ODI_Batswoman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: iii)  Top 10 women’s ODI all-rounder along with the records of their team and  rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1        This player h...</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8        T...</td>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9        T...</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Ranking            Player Team  \\\n",
       "0                          1        This player h...    Marizanne Kapp   SA   \n",
       "1                                                ...      Ellyse Perry  AUS   \n",
       "2                                          3           Stafanie Taylor   WI   \n",
       "3                                          4            Natalie Sciver  ENG   \n",
       "4                                          5             Deepti Sharma  IND   \n",
       "5                                          6             Jess Jonassen  AUS   \n",
       "6                                          7          Ashleigh Gardner  AUS   \n",
       "7                                      8        T...  Dane van Niekerk   SA   \n",
       "8                                      9        T...     Sophie Devine   NZ   \n",
       "9                                      10        ...       Amelia Kerr   NZ   \n",
       "\n",
       "  Rating  \n",
       "0    418  \n",
       "1    418  \n",
       "2    410  \n",
       "3    349  \n",
       "4    343  \n",
       "5    307  \n",
       "6    252  \n",
       "7    243  \n",
       "8    242  \n",
       "9    236  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "top_position=soup.find_all('div', class_=\"rankings-block__banner--pos\")\n",
    "top_player=soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "top_nationality=soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "\n",
    "banner_position=top_position[2].text.replace('\\n','')\n",
    "banner_player=top_player[2].text.replace('\\n','')\n",
    "str=top_nationality[2].text.replace('\\n','')\n",
    "\n",
    "banner_team = ''\n",
    "banner_rating=''\n",
    "\n",
    "for i in str:\n",
    "    if i.isalpha():\n",
    "        banner_team += i\n",
    "    \n",
    "    if i.isdigit():\n",
    "        banner_rating += i\n",
    "\n",
    "\n",
    "position=soup.find_all('td',class_=\"table-body__cell table-body__cell--position u-text-right\")\n",
    "player=soup.find_all('td',class_='table-body__cell name')\n",
    "country=soup.find_all('td', class_=\"table-body__cell nationality-logo\")\n",
    "rating=soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "\n",
    "ranking=[]\n",
    "player_name=[]\n",
    "team=[]\n",
    "player_rating=[]\n",
    "\n",
    "ranking.append(banner_position)\n",
    "player_name.append(banner_player)\n",
    "team.append(banner_team)\n",
    "player_rating.append(banner_rating)\n",
    "\n",
    "for i in range(18,27):\n",
    "    ranking.append(position[i].text.replace('\\n',''))\n",
    "    player_name.append(player[i].text.replace('\\n',''))\n",
    "    team.append(country[i].text.replace('\\n',''))\n",
    "    player_rating.append(rating[i].text)\n",
    "        \n",
    "Top10_ODI_Women_Allrounder=pd.DataFrame({'Ranking':(ranking),\n",
    "                               'Player':(player_name),\n",
    "                               'Team':(team),\n",
    "                               'Rating':(player_rating)})\n",
    "\n",
    "Top10_ODI_Women_Allrounder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Write  a  python  program to  extract information  about  the local  weather from the  National Weather  Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended  forecast  display  for  the  city.  The  data  should  include  period,  short  description,  temperature  and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>temp</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ThisAfternoon</td>\n",
       "      <td>Sunny andBreezy</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>This Afternoon: Sunny, with a high near 69. Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>IncreasingClouds</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Tonight: Increasing clouds, with a low around ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Partly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Monday: Mostly cloudy, then gradually becoming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MondayNight</td>\n",
       "      <td>Partly Cloudyand Breezythen MostlyCloudy</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "      <td>Monday Night: Increasing clouds, with a low ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Partly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Tuesday: Mostly sunny, with a high near 69. Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TuesdayNight</td>\n",
       "      <td>Mostly Clearand Breezythen MostlyCloudy</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Tuesday Night: Partly cloudy, with a low aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 68 °F</td>\n",
       "      <td>Wednesday: Mostly sunny, with a high near 68.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WednesdayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Wednesday Night: Partly cloudy, with a low aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Thursday: Mostly sunny, with a high near 69.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           period                                short_desc         temp  \\\n",
       "0   ThisAfternoon                           Sunny andBreezy  High: 69 °F   \n",
       "1         Tonight                          IncreasingClouds   Low: 56 °F   \n",
       "2          Monday          Partly Sunnythen Sunnyand Breezy  High: 69 °F   \n",
       "3     MondayNight  Partly Cloudyand Breezythen MostlyCloudy   Low: 58 °F   \n",
       "4         Tuesday          Partly Sunnythen Sunnyand Breezy  High: 69 °F   \n",
       "5    TuesdayNight   Mostly Clearand Breezythen MostlyCloudy   Low: 57 °F   \n",
       "6       Wednesday                              Mostly Sunny  High: 68 °F   \n",
       "7  WednesdayNight                             Partly Cloudy   Low: 56 °F   \n",
       "8        Thursday                              Mostly Sunny  High: 69 °F   \n",
       "\n",
       "                                                desc  \n",
       "0  This Afternoon: Sunny, with a high near 69. Br...  \n",
       "1  Tonight: Increasing clouds, with a low around ...  \n",
       "2  Monday: Mostly cloudy, then gradually becoming...  \n",
       "3  Monday Night: Increasing clouds, with a low ar...  \n",
       "4  Tuesday: Mostly sunny, with a high near 69. Br...  \n",
       "5  Tuesday Night: Partly cloudy, with a low aroun...  \n",
       "6      Wednesday: Mostly sunny, with a high near 68.  \n",
       "7  Wednesday Night: Partly cloudy, with a low aro...  \n",
       "8       Thursday: Mostly sunny, with a high near 69.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "tonight = forecast_items[0]\n",
    "#print(tonight.prettify())\n",
    "\n",
    "period=tonight.find(class_='period-name').get_text()\n",
    "short_desc=tonight.find(class_='short-desc').get_text()\n",
    "temp=tonight.find(class_='temp').get_text()\n",
    "\n",
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "\n",
    "period_tags=seven_day.select('.tombstone-container .period-name')\n",
    "periods=[pt.get_text() for pt in period_tags]\n",
    "\n",
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "\n",
    "weather = pd.DataFrame({\n",
    "        \"period\": periods,\n",
    "         \"short_desc\": short_descs,\n",
    "         \"temp\": temps,\n",
    "         \"desc\":descs\n",
    "    })\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Write a python program to  scrape fresher job  listings from  ‘https://internshala.com/’. It should  include job  title,  company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Manufac Analytics Private Limited</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Software Engineer Trainee</td>\n",
       "      <td>Swabhav Techlabs</td>\n",
       "      <td>3 - 3.5 LPA                                 ...</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Development Specialist (Sales &amp; Marke...</td>\n",
       "      <td>Claraeon Learning Private Limited</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Picostone</td>\n",
       "      <td>3 - 6.5 LPA                                 ...</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>6 - 7 LPA                                   ...</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Corporate Sales Executive</td>\n",
       "      <td>369 Zoss Waters</td>\n",
       "      <td>3 - 5 LPA                                   ...</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Associate Software Developer (Full-Stack - Rea...</td>\n",
       "      <td>SleekSky LLC</td>\n",
       "      <td>4 LPA                                       ...</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Customer Relationship Specialist</td>\n",
       "      <td>InPhase Power Technologies</td>\n",
       "      <td>3 - 3.5 LPA                                 ...</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Editor Engagement</td>\n",
       "      <td>Cactus Communications Private Limited</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Management Consultant Associate</td>\n",
       "      <td>StrategyCo.Global</td>\n",
       "      <td>4.5 - 7 LPA                                 ...</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Web Analytics Developer</td>\n",
       "      <td>DataVinci Private Limited</td>\n",
       "      <td>4.99 - 5 LPA                                ...</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Junior Social Media Marketing Manager</td>\n",
       "      <td>The Test Tribe</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Junior Social Media Marketing Associate</td>\n",
       "      <td>Glu Studios</td>\n",
       "      <td>3 - 3.6 LPA                                 ...</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Business Development Manager (Digital Marketin...</td>\n",
       "      <td>Graygraph Technologies LLC</td>\n",
       "      <td>3 - 4.5 LPA                                 ...</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>BookLeaf Publishing</td>\n",
       "      <td>3 - 3.6 LPA                                 ...</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>Ravi Ladia &amp; Co</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Research Associate</td>\n",
       "      <td>Market Vistas Consumer Insights</td>\n",
       "      <td>3 - 3.25 LPA                                ...</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Assistant Coordinator - Tender Department</td>\n",
       "      <td>Global Source Trading LLC</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Customer Relationship Manager (Publishing Cons...</td>\n",
       "      <td>Blue Rose Publishers</td>\n",
       "      <td>3 - 3.5 LPA                                 ...</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Executive Assistant To Director</td>\n",
       "      <td>Best Roadways Limited</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Learning Consultant - Sales</td>\n",
       "      <td>Geekster</td>\n",
       "      <td>3 - 3.5 LPA                                 ...</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>School/Teacher Consultant</td>\n",
       "      <td>InfyBytes AI Labs Private Limited</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Junior Recruiter</td>\n",
       "      <td>Radish Consultants Private Limited</td>\n",
       "      <td>3 - 5 LPA                                   ...</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Moxie.xyz</td>\n",
       "      <td>9 LPA                                       ...</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>3.75 LPA                                    ...</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Fullmoon Outdoor Web Solutions</td>\n",
       "      <td>4 - 4.2 LPA                                 ...</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Order Processor</td>\n",
       "      <td>InspectHOA</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Nikulsan Technologies Private Limited</td>\n",
       "      <td>3.5 - 5 LPA                                 ...</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>IQGateway</td>\n",
       "      <td>3.6 - 10 LPA                                ...</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3.3 - 4 LPA                                 ...</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Varenyam Placements</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>HealthPlix Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Inside Sales Associate</td>\n",
       "      <td>Wizklub Learning</td>\n",
       "      <td>3 - 6 LPA                                   ...</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Mobile App Developer</td>\n",
       "      <td>Fusion Engineering</td>\n",
       "      <td>4.5 - 5.25 LPA                              ...</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Junior MERN Stack Developer</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA                                   ...</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Education Innovation Manager</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA                                   ...</td>\n",
       "      <td>10 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>General Management Associate</td>\n",
       "      <td>Redwood Algorithms</td>\n",
       "      <td>4 - 5 LPA                                   ...</td>\n",
       "      <td>10 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Content &amp; E-commerce Management Trainee</td>\n",
       "      <td>Blooprint Ecom Consulting</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>QuikieApps</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                                      Web Developer    \n",
       "1                          Software Engineer Trainee    \n",
       "2   Business Development Specialist (Sales & Marke...   \n",
       "3                     Business Development Executive    \n",
       "4                      Associate Front End Developer    \n",
       "5                          Corporate Sales Executive    \n",
       "6   Associate Software Developer (Full-Stack - Rea...   \n",
       "7                   Customer Relationship Specialist    \n",
       "8                        Associate Editor Engagement    \n",
       "9                    Management Consultant Associate    \n",
       "10                           Web Analytics Developer    \n",
       "11             Junior Social Media Marketing Manager    \n",
       "12           Junior Social Media Marketing Associate    \n",
       "13  Business Development Manager (Digital Marketin...   \n",
       "14                    Business Development Executive    \n",
       "15                                        Accountant    \n",
       "16                                Research Associate    \n",
       "17         Assistant Coordinator - Tender Department    \n",
       "18  Customer Relationship Manager (Publishing Cons...   \n",
       "19                   Executive Assistant To Director    \n",
       "20                       Learning Consultant - Sales    \n",
       "21                         School/Teacher Consultant    \n",
       "22                                  Junior Recruiter    \n",
       "23                                Software Developer    \n",
       "24     Business Development Executive (Inside Sales)    \n",
       "25                                     Web Developer    \n",
       "26                                   Order Processor    \n",
       "27                              Full Stack Developer    \n",
       "28                      Associate Software Developer    \n",
       "29                                 Reactjs Developer    \n",
       "30                              Full Stack Developer    \n",
       "31                    Business Development Executive    \n",
       "32                         Corporate Sales Associate    \n",
       "33                            Inside Sales Associate    \n",
       "34                              Mobile App Developer    \n",
       "35                       Junior MERN Stack Developer    \n",
       "36                      Education Innovation Manager    \n",
       "37                      General Management Associate    \n",
       "38           Content & E-commerce Management Trainee    \n",
       "39                                 Software Engineer    \n",
       "\n",
       "                                       Company Name  \\\n",
       "0                 Manufac Analytics Private Limited   \n",
       "1                                  Swabhav Techlabs   \n",
       "2                 Claraeon Learning Private Limited   \n",
       "3                                         Picostone   \n",
       "4                    AIMonk Labs Technology Limited   \n",
       "5                                   369 Zoss Waters   \n",
       "6                                      SleekSky LLC   \n",
       "7                        InPhase Power Technologies   \n",
       "8             Cactus Communications Private Limited   \n",
       "9                                 StrategyCo.Global   \n",
       "10                        DataVinci Private Limited   \n",
       "11                                   The Test Tribe   \n",
       "12                                      Glu Studios   \n",
       "13                       Graygraph Technologies LLC   \n",
       "14                              BookLeaf Publishing   \n",
       "15                                  Ravi Ladia & Co   \n",
       "16                  Market Vistas Consumer Insights   \n",
       "17                        Global Source Trading LLC   \n",
       "18                             Blue Rose Publishers   \n",
       "19                            Best Roadways Limited   \n",
       "20                                         Geekster   \n",
       "21                InfyBytes AI Labs Private Limited   \n",
       "22               Radish Consultants Private Limited   \n",
       "23                                        Moxie.xyz   \n",
       "24                                          GREedge   \n",
       "25                   Fullmoon Outdoor Web Solutions   \n",
       "26                                       InspectHOA   \n",
       "27            Nikulsan Technologies Private Limited   \n",
       "28                                        IQGateway   \n",
       "29          Startxlabs Technologies Private Limited   \n",
       "30  RavGins International Private Limited (Wobb.ai)   \n",
       "31                              Varenyam Placements   \n",
       "32          HealthPlix Technologies Private Limited   \n",
       "33                                 Wizklub Learning   \n",
       "34                               Fusion Engineering   \n",
       "35     DeepThought Edutech Ventures Private Limited   \n",
       "36     DeepThought Edutech Ventures Private Limited   \n",
       "37                               Redwood Algorithms   \n",
       "38                        Blooprint Ecom Consulting   \n",
       "39                                       QuikieApps   \n",
       "\n",
       "                                                  CTC  Apply Date  \n",
       "0     3 - 4 LPA                                   ...  19 Jul' 21  \n",
       "1     3 - 3.5 LPA                                 ...  19 Jul' 21  \n",
       "2     3 LPA                                       ...  19 Jul' 21  \n",
       "3     3 - 6.5 LPA                                 ...  19 Jul' 21  \n",
       "4     6 - 7 LPA                                   ...  18 Jul' 21  \n",
       "5     3 - 5 LPA                                   ...  18 Jul' 21  \n",
       "6     4 LPA                                       ...  18 Jul' 21  \n",
       "7     3 - 3.5 LPA                                 ...  18 Jul' 21  \n",
       "8     3 - 4 LPA                                   ...  18 Jul' 21  \n",
       "9     4.5 - 7 LPA                                 ...  18 Jul' 21  \n",
       "10    4.99 - 5 LPA                                ...  17 Jul' 21  \n",
       "11    3 - 4 LPA                                   ...  17 Jul' 21  \n",
       "12    3 - 3.6 LPA                                 ...  17 Jul' 21  \n",
       "13    3 - 4.5 LPA                                 ...  17 Jul' 21  \n",
       "14    3 - 3.6 LPA                                 ...  17 Jul' 21  \n",
       "15    3 LPA                                       ...  16 Jul' 21  \n",
       "16    3 - 3.25 LPA                                ...  17 Jul' 21  \n",
       "17    3 LPA                                       ...  16 Jul' 21  \n",
       "18    3 - 3.5 LPA                                 ...  16 Jul' 21  \n",
       "19    3 LPA                                       ...  17 Jul' 21  \n",
       "20    3 - 3.5 LPA                                 ...  16 Jul' 21  \n",
       "21    3 - 4 LPA                                   ...  16 Jul' 21  \n",
       "22    3 - 5 LPA                                   ...  16 Jul' 21  \n",
       "23    9 LPA                                       ...  15 Jul' 21  \n",
       "24    3.75 LPA                                    ...  15 Jul' 21  \n",
       "25    4 - 4.2 LPA                                 ...  15 Jul' 21  \n",
       "26    3 LPA                                       ...  14 Jul' 21  \n",
       "27    3.5 - 5 LPA                                 ...  14 Jul' 21  \n",
       "28    3.6 - 10 LPA                                ...  11 Jul' 21  \n",
       "29    3 - 4 LPA                                   ...  11 Jul' 21  \n",
       "30    3.3 - 4 LPA                                 ...  11 Jul' 21  \n",
       "31    3 - 4 LPA                                   ...  11 Jul' 21  \n",
       "32    3 - 4 LPA                                   ...  11 Jul' 21  \n",
       "33    3 - 6 LPA                                   ...  11 Jul' 21  \n",
       "34    4.5 - 5.25 LPA                              ...  14 Jul' 21  \n",
       "35    3 - 5 LPA                                   ...  15 Jul' 21  \n",
       "36    3 - 5 LPA                                   ...  10 Jul' 21  \n",
       "37    4 - 5 LPA                                   ...  10 Jul' 21  \n",
       "38    3 LPA                                       ...   9 Jul' 21  \n",
       "39    3 - 4 LPA                                   ...   9 Jul' 21  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://internshala.com/fresher-jobs')\n",
    "soup=BeautifulSoup(page.content)\n",
    "titles=soup.find_all('div',class_='heading_4_5 profile')\n",
    "companies=soup.find_all('div',class_=\"heading_6 company_name\")\n",
    "details=soup.find_all('div',class_='item_body')\n",
    "\n",
    "jt=[]\n",
    "company=[]\n",
    "salary=[]\n",
    "apply_date=[]\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    jt.append(titles[i].text.replace('\\n',''))\n",
    "    company.append(companies[i].text.strip())\n",
    "    salary.append(details[3*i+1].text.replace('\\n',''))\n",
    "    apply_date.append(details[3*i+2].text)\n",
    "    \n",
    "Jobs=pd.DataFrame({'Job Title':(jt),\n",
    "                  'Company Name':(company),\n",
    "                  'CTC':(salary),\n",
    "                  'Apply Date':(apply_date)})\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Write a python program to scrape house details  from mentioned url. It should include house title, location,  area, emi and price https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 BHK Flat  For Sale  In Purnima Elite, Electr...</td>\n",
       "      <td>Purnima Elite, Phase 1, Kammasandra, Electroni...</td>\n",
       "      <td>995 sqft</td>\n",
       "      <td>₹23,498/Month</td>\n",
       "      <td>₹41 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Icon Happy Livin...</td>\n",
       "      <td>Icon Happy Living   Opp Hebagodi Metro station...</td>\n",
       "      <td>765 sqft</td>\n",
       "      <td>₹24,645/Month</td>\n",
       "      <td>₹43 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Gm Infinite E-ci...</td>\n",
       "      <td>Gm Infinite E-City Town  GM Infinite ECity tow...</td>\n",
       "      <td>1,070 sqft</td>\n",
       "      <td>₹33,242/Month</td>\n",
       "      <td>₹58 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Mahendra Aarna I...</td>\n",
       "      <td>Mahendra Aarna  Opp Grand Mart Hyper Market, P...</td>\n",
       "      <td>1,380 sqft</td>\n",
       "      <td>₹47,571/Month</td>\n",
       "      <td>₹83 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 BHK Flat  For Sale  In Smondo 2.0, Electroni...</td>\n",
       "      <td>Neotown Road, Electronic City, Electronics Cit...</td>\n",
       "      <td>1,460 sqft</td>\n",
       "      <td>₹41,266/Month</td>\n",
       "      <td>₹72 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Ds Sigma Nest In...</td>\n",
       "      <td>Ds Sigma Nest  Gollahalli, Explore Nearby</td>\n",
       "      <td>1,240 sqft</td>\n",
       "      <td>₹31,522/Month</td>\n",
       "      <td>₹55 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3 BHK Flat  For Sale  In Shobha Silicon Oasis ...</td>\n",
       "      <td>Central Jail Rd, Chennakeshava Nagar, Hosa Roa...</td>\n",
       "      <td>1,580 sqft</td>\n",
       "      <td>₹80,240/Month</td>\n",
       "      <td>₹1.4 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Smondo 3.0 In El...</td>\n",
       "      <td>Smondo 3.0  Neotown Rd, Neotown, Electronic Ci...</td>\n",
       "      <td>1,275 sqft</td>\n",
       "      <td>₹33,242/Month</td>\n",
       "      <td>₹58 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Bomm...</td>\n",
       "      <td>Independent House, Bommasandra Indl Area, RK T...</td>\n",
       "      <td>5,400 sqft</td>\n",
       "      <td>₹75,655/Month</td>\n",
       "      <td>₹1.32 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Abode Breeze Apa...</td>\n",
       "      <td>Abode Breeze Apartments  Kammasandra Rd, RS Ga...</td>\n",
       "      <td>1,326 sqft</td>\n",
       "      <td>₹35,534/Month</td>\n",
       "      <td>₹62 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         House Title  \\\n",
       "0  2 BHK Flat  For Sale  In Purnima Elite, Electr...   \n",
       "1  2 BHK Apartment  For Sale  In Icon Happy Livin...   \n",
       "2  2 BHK Apartment  For Sale  In Gm Infinite E-ci...   \n",
       "3  3 BHK Apartment  For Sale  In Mahendra Aarna I...   \n",
       "4  3 BHK Flat  For Sale  In Smondo 2.0, Electroni...   \n",
       "5  2 BHK Apartment  For Sale  In Ds Sigma Nest In...   \n",
       "6  3 BHK Flat  For Sale  In Shobha Silicon Oasis ...   \n",
       "7  3 BHK Apartment  For Sale  In Smondo 3.0 In El...   \n",
       "8  4+ BHK In Independent House  For Sale  In Bomm...   \n",
       "9  3 BHK Apartment  For Sale  In Abode Breeze Apa...   \n",
       "\n",
       "                                            Location        Area  \\\n",
       "0  Purnima Elite, Phase 1, Kammasandra, Electroni...    995 sqft   \n",
       "1  Icon Happy Living   Opp Hebagodi Metro station...    765 sqft   \n",
       "2  Gm Infinite E-City Town  GM Infinite ECity tow...  1,070 sqft   \n",
       "3  Mahendra Aarna  Opp Grand Mart Hyper Market, P...  1,380 sqft   \n",
       "4  Neotown Road, Electronic City, Electronics Cit...  1,460 sqft   \n",
       "5          Ds Sigma Nest  Gollahalli, Explore Nearby  1,240 sqft   \n",
       "6  Central Jail Rd, Chennakeshava Nagar, Hosa Roa...  1,580 sqft   \n",
       "7  Smondo 3.0  Neotown Rd, Neotown, Electronic Ci...  1,275 sqft   \n",
       "8  Independent House, Bommasandra Indl Area, RK T...  5,400 sqft   \n",
       "9  Abode Breeze Apartments  Kammasandra Rd, RS Ga...  1,326 sqft   \n",
       "\n",
       "             EMI         Price  \n",
       "0  ₹23,498/Month      ₹41 Lacs  \n",
       "1  ₹24,645/Month      ₹43 Lacs  \n",
       "2  ₹33,242/Month      ₹58 Lacs  \n",
       "3  ₹47,571/Month      ₹83 Lacs  \n",
       "4  ₹41,266/Month      ₹72 Lacs  \n",
       "5  ₹31,522/Month      ₹55 Lacs  \n",
       "6  ₹80,240/Month   ₹1.4 Crores  \n",
       "7  ₹33,242/Month      ₹58 Lacs  \n",
       "8  ₹75,655/Month  ₹1.32 Crores  \n",
       "9  ₹35,534/Month      ₹62 Lacs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = requests.get('https://www.nobroker.in/property/sale/bangalore/Electronic%20City?searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&radius=2.0')\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "titles=soup.find_all('a',class_='nb__3CnI6')\n",
    "loc=soup.find_all('div',class_=\"nb__35Ol7\")\n",
    "details=soup.find_all('div',class_='font-semi-bold heading-6')\n",
    "#area=soup.find_all('div',class_='nb__3oNyC')\n",
    "#EMI=soup.find_all('div',class_='nb__2NPHR')\n",
    "\n",
    "house=[]\n",
    "location=[]\n",
    "area=[]\n",
    "EMI=[]\n",
    "price=[]\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    house.append(titles[i].text)\n",
    "    location.append(loc[i].text)\n",
    "    area.append(details[3*i].text)\n",
    "    EMI.append(details[3*i+1].text)\n",
    "    price.append(details[3*i+2].text)\n",
    "    \n",
    "Property=pd.DataFrame({'House Title':(house),\n",
    "                  'Location':(location),\n",
    "                  'Area':(area),\n",
    "                  'EMI':(EMI),\n",
    "                    'Price':(price)})\n",
    "Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
